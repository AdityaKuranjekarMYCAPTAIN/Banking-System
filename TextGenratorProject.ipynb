{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO8MgNalUTzAGB1z9haWVqS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdityaKuranjekarMYCAPTAIN/Banking-System/blob/main/TextGenratorProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lm-_8qZhj7jD"
      },
      "outputs": [],
      "source": [
        "#import dependencies\n",
        "import numpy\n",
        "import sys\n",
        "import nltk\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, LSTM\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load data\n",
        "# loading data and opening our input data in the form of txt form\n",
        "# Project Gutenberg/berg is where the data can be jound (Just google it)\n",
        "file = open(\"/Frankenstein.txt\", encoding='latin-1').read()"
      ],
      "metadata": {
        "id": "9JkXhtfWVdzX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenization is the process of breaking a big piece of text, like a sentence or paragraph, into smaller parts called tokens. These tokens can be words, phrases, or even individual characters, depending on the purpose."
      ],
      "metadata": {
        "id": "O33BDkr8imHi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenization\n",
        "# WHat is tokanization? Process of breaking a stream of text into words, phrase or symbols or meaningful elements\n",
        "# standardization\n",
        "nltk.download('stopwords')\n",
        "def tokenize_words(input):\n",
        "  # Lowercase everything to standardize it\n",
        "  input = input.lower()\n",
        "  # Initiating tokenizer\n",
        "  tokenizer = RegexpTokenizer(r'\\w+')\n",
        "  tokens = tokenizer.tokenize(input)\n",
        "  # Filtering the stopwords using lambda\n",
        "  filtered = filter(lambda token: token not in stopwords.words('english'), tokens)\n",
        "  return \"\".join(filtered)\n",
        "\n",
        "# Preprocessing the input data, make tokens\n",
        "processed_inputs = tokenize_words(file)"
      ],
      "metadata": {
        "id": "D4WISgeOXIhB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d46f7d72-e34a-4b7f-efad-2bccdc176e24"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our Tokenization task is now completed"
      ],
      "metadata": {
        "id": "cTcXAP5wiR0O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nural network essentially wok with numbers not chaarcters.\n",
        "So we have to convert char into numbers"
      ],
      "metadata": {
        "id": "3H8lmHrBiqa_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Char to numbers\n",
        "# Convert characters in our input to numbers\n",
        "# we'll sort the list of the set of all characters that appera in out i/p text and then enumerate fn\n",
        "# to get numbers that represent the chaaracters\n",
        "# we'll then create dictionaries that stores the key and value, or the characters and numbers that represent them\n",
        "chars = sorted(list(set(processed_inputs)))\n",
        "char_to_num = dict((c, i) for i, c in enumerate(chars))"
      ],
      "metadata": {
        "id": "TKsVVNKyiYG-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if the words to chars or chars to num is worked??\n",
        "# just so that we get idea of weather our process of converting words into char has worked\n",
        "# We print the length of out variables\n",
        "input_len = len(processed_inputs)\n",
        "vocab_len = len(chars)\n",
        "print (\"Total number of characters:\", input_len)\n",
        "print (\"Total vocab:\", vocab_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDZwWvEmjS4W",
        "outputId": "3d04fa67-1c1b-4051-a660-852c15b3ceee"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of characters: 212998\n",
            "Total vocab: 41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Seq length\n",
        "# we're defining how long we want individual sequence\n",
        "# an individual sequence is an complete mapping of input characters as integers\n",
        "seq_length = 100\n",
        "x_data = []\n",
        "y_data = []"
      ],
      "metadata": {
        "id": "zKait4PAjjCO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loop through the sequence\n",
        "# here we are going through the entire lists of i/ps and converting the chars to numbres with a for loop\n",
        "# this will create bunch of sequence where each sequence starrts with the next char in the i/p data\n",
        "# beginning with the first character\n",
        "for i in range(0, input_len - seq_length, 1):\n",
        "  # define i/p and o/p sequence\n",
        "  # i/p is current character plus the desired sequence length\n",
        "  in_seq = processed_inputs[i:i + seq_length]\n",
        "  # out sequence is the initial character plus total sequence length\n",
        "  out_seq = processed_inputs[i + seq_length]\n",
        "  # Converting the list of characters to integers based on previous values and appending the values to or list\n",
        "  x_data.append([char_to_num[char] for char in in_seq])\n",
        "  y_data.append(char_to_num[out_seq])\n",
        "\n",
        "# Check to see how many total input seuence we have\n",
        "n_patterns = len(x_data)\n",
        "print (\"Total Patterns:\", n_patterns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3KuMVV_jnfy",
        "outputId": "2480a2b9-5e16-41f9-de77-9f1796f86c9f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Patterns: 212898\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert input sequence to np array that our network can use\n",
        "X = numpy.reshape(x_data, (n_patterns, seq_length, 1))\n",
        "X = X/float(vocab_len)"
      ],
      "metadata": {
        "id": "1-M00v7kj1MF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# one-hot encoding our label data\n",
        "y = to_categorical(y_data)"
      ],
      "metadata": {
        "id": "pePo0nV6j9Ze"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the model\n",
        "# creating sequential model\n",
        "# Dropout is used to prevent overfitting\n",
        "# LSTM\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(256, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MONLFp5wlDm8",
        "outputId": "917d9f94-147a-4734-f18f-f5fdd5ab59d7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "metadata": {
        "id": "ZrRBehehlhHn"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# saving weights\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# Saving weights with .keras format (recommended for TensorFlow >= 2.6)\n",
        "filepath = \"model_weights_saved.keras\"  # Change extension to .keras\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "desired_callbacks = [checkpoint]"
      ],
      "metadata": {
        "id": "K_lbwPDWllwW"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit model and let it train\n",
        "model.fit(X, y, epochs=4, batch_size=256, callbacks=desired_callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22CLfBQVmyxO",
        "outputId": "0771ad7d-bd9c-4bbd-f974-20f795e33749"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "\u001b[1m832/832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - loss: 2.9742\n",
            "Epoch 1: loss improved from inf to 2.93354, saving model to model_weights_saved.keras\n",
            "\u001b[1m832/832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3377s\u001b[0m 4s/step - loss: 2.9742\n",
            "Epoch 2/4\n",
            "\u001b[1m832/832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - loss: 2.9077\n",
            "Epoch 2: loss improved from 2.93354 to 2.91030, saving model to model_weights_saved.keras\n",
            "\u001b[1m832/832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3367s\u001b[0m 4s/step - loss: 2.9077\n",
            "Epoch 3/4\n",
            "\u001b[1m832/832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - loss: 2.9043\n",
            "Epoch 3: loss improved from 2.91030 to 2.90503, saving model to model_weights_saved.keras\n",
            "\u001b[1m832/832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3379s\u001b[0m 4s/step - loss: 2.9043\n",
            "Epoch 4/4\n",
            "\u001b[1m832/832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - loss: 2.8861\n",
            "Epoch 4: loss improved from 2.90503 to 2.87842, saving model to model_weights_saved.keras\n",
            "\u001b[1m832/832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3372s\u001b[0m 4s/step - loss: 2.8861\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78bc8de56080>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# recompile model with saved weights\n",
        "filename = \"model_weights_saved.keras\"\n",
        "model.load_weights(filename)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "metadata": {
        "id": "ESjieZ-bm8qE"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# output of the model back into chatacter\n",
        "num_to_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "metadata": {
        "id": "q574QVB4pY8h"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# random seed to help generate\n",
        "start = numpy.random.randint(0, len(x_data) - 1)\n",
        "pattern = x_data[start]\n",
        "print(\"Random Seed:\")\n",
        "print(\"\\\"\", ' '.join([num_to_char[value] for value in pattern]), \"\\\" \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gMSvtMApvfL",
        "outputId": "dec663a1-bd68-4ffc-bcbd-8f8f965d865d"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Seed:\n",
            "\" e r e d c h a s e a w a y i d l e f e a r s a l o n e c o n s e c r a t e l i f e e n d e a v o u r s c o n t e n t m e n t o n e s e c r e t e l i z a b e t h d r e a d f u l o n e r e v e a l e d c \" \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# generate the text\n",
        "for i in range(1000):\n",
        "  x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "  x = x / float(vocab_len)\n",
        "  prediction = model.predict(x, verbose=0)\n",
        "  index = numpy.argmax(prediction)\n",
        "  result = num_to_char[index]\n",
        "  seq_in = [num_to_char[value] for value in pattern]\n",
        "  sys.stdout.write(result)\n",
        "  pattern.append(index)\n",
        "  pattern = pattern[1:len(pattern)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "ofgFhgcjqHn8",
        "outputId": "f0c41035-5dc6-49a2-a203-f6794e5a7aa1"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "input_dataset: Attempting to capture an EagerTensor without building a function.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-66ddeb7ebf33>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_to_char\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__tf_tensor__\u001b[0;34m(self, dtype, name)\u001b[0m\n\u001b[1;32m    600\u001b[0m       \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilding_function\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m         raise RuntimeError(\n\u001b[0m\u001b[1;32m    603\u001b[0m             _add_error_prefix(\n\u001b[1;32m    604\u001b[0m                 \u001b[0;34m\"Attempting to capture an EagerTensor without \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: input_dataset: Attempting to capture an EagerTensor without building a function."
          ]
        }
      ]
    }
  ]
}